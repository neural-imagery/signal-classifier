{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34aafaad",
   "metadata": {},
   "source": [
    "assumes data is in `./data_movie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f95fb88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15badfa3",
   "metadata": {},
   "source": [
    "The entire goal of this notebook is to fill the events and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0201bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_labels_dic = {\n",
    "    \"planetearth\":0,\n",
    "    \"animatedshorts\":1,\n",
    "    \"3b1b\":2,\n",
    "    \"jackychan\":3,\n",
    "    \"mandarinvocab\":4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7236169",
   "metadata": {},
   "source": [
    "We will only load occipital lobe data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "53f6fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 10.0 # 10 Hz sample rate\n",
    "ETIME = 5.0 # defines time of event to be 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e5083305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(snirf_path=\"data_movie/steve-scan1-Sep-21-2023-6-35-PM_run02.snirf\",\n",
    "               tsv_path=\"data_movie/timestamps_run02.tsv\"):\n",
    "    intensity = mne.io.read_raw_snirf(snirf_path)\n",
    "    annots_df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "    onsets = annots_df.Onset.tolist()\n",
    "#     idx_to_type = list(set(annots_df.trial_type))\n",
    "#     type_to_idx = {type_:idx for idx, type_ in enumerate(idx_to_type)}\n",
    "    durations = list(np.array(onsets[1:]) - np.array(onsets[:-1])) + [0]\n",
    "    annots = mne.Annotations(\n",
    "        onset=onsets,  # in seconds (interprets as ctime)\n",
    "        duration=durations,  # in seconds, too\n",
    "        description=annots_df.trial_type.tolist(),\n",
    "    )\n",
    "    intensity = intensity.set_annotations(annots)\n",
    "    return intensity,annots_df,onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e05ae0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRAMELEN = 128\n",
    "# SR = 10.0 # 10 Hz Sample Rate\n",
    "# def spec(ts,sr:float=10.0):\n",
    "#     win = np.hamming(FRAMELEN)\n",
    "#     slideby = FRAMELEN//4 # hard coded bad\n",
    "#     nframes = len(ts)//slideby - 3\n",
    "#     freqs = np.fft.rfftfreq(FRAMELEN,1/sr)\n",
    "#     s=[]\n",
    "#     for i in range(nframes):\n",
    "#         idx_start = i*slideby\n",
    "#         s.append(np.fft.rfft(ts[idx_start:idx_start+FRAMELEN] * win))\n",
    "#     s = np.asarray(s)\n",
    "#     times = np.arange(0,s.shape[0]) *slideby/sr\n",
    "#     return s,freqs,times\n",
    "# \n",
    "# s,freqs,times=spec(np.squeeze(od[0][0])[1000:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76267933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_spec_grid(od, ch_names, tstart:float, tend:float, event_times=[0],title=None,saveas=None):\n",
    "    \"\"\"od is an optical density mne object\n",
    "    \n",
    "    event_times : list\n",
    "        time of all the events, in seconds from start of file\n",
    "    \"\"\"\n",
    "    tidx_start = int(tstart * SR)\n",
    "    tidx_end = int(tend * SR)\n",
    "    spec_data = [spec(np.squeeze(od[idx][0])[tidx_start:tidx_end]) for idx in range(32)]\n",
    "    fig, axes = plt.subplots(nrows=8, ncols=4, figsize=(15, 25))\n",
    "\n",
    "    for idx_ch,(ax,(s,freqs,times),ch_name) in enumerate(zip(axes.ravel(), spec_data, ch_names)):\n",
    "        times += tstart # compensate for offset\n",
    "        im = ax.imshow(10*np.log10(abs(s)**2), aspect='auto',cmap='plasma', vmin=-140, vmax=-70) #,vmin=-45,vmax=25)\n",
    "        ax.set_xticks(np.arange(0,s.shape[1],s.shape[1]//6), [f\"{i:.2f}\" for i in freqs[::s.shape[1]//6]], \n",
    "                      rotation=-10, fontsize=7.0)\n",
    "        ax.set_xlabel(\"Freqs (Hz)\")\n",
    "        ax.set_yticks(np.arange(0,s.shape[0],s.shape[0]//5), [f\"{i:.1f}\" for i in times[::s.shape[0]//5]],fontsize=7.0)\n",
    "        ax.set_ylabel(\"Time (s)\")\n",
    "        ax.set_title(f\"{ch_name}\")\n",
    "        for e in event_times:\n",
    "            ax.axhline((e-tstart)*SR/(FRAMELEN//4),color='green',lw=1)\n",
    "        # Colorbar for each subplot\n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        \n",
    "        # If you want the same scale for all, set vmin and vmax in imshow\n",
    "        # im = ax.imshow(dat, aspect='auto', vmin=min_value, vmax=max_value)\n",
    "    if title: \n",
    "        plt.suptitle(f\"{title}\",fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    if saveas:\n",
    "        plt.savefig(saveas,dpi=400)\n",
    "    plt.show()\n",
    "# plot_spec_grid(od,tstart=onsets[0],tend=onsets[-1]+20,event_times=onsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dbd28fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/steve/Documents/code/neuroimagery2023/signal-classifier/data_movie/steve-scan1-Sep-21-2023-6-35-PM_run02.snirf\n",
      "Reading 0 ... 13012  =      0.000 ...  1301.200 secs...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['S2_D3 hbo', 'S2_D4 hbo', 'S3_D5 hbo', 'S3_D6 hbo']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intensity,annots_df,onsets = load_files(join(\"data_movie\",\"steve-scan1-Sep-21-2023-6-35-PM_run02.snirf\"),\n",
    "                                        join(\"data_movie\",\"timestamps_run02.tsv\"))\n",
    "od = mne.preprocessing.nirs.optical_density(intensity)\n",
    "raw_hemo = mne.preprocessing.nirs.beer_lambert_law(od)\n",
    "picks = [\"S2_D3 hbo\", \"S2_D4 hbo\", \"S3_D5 hbo\", \"S3_D6 hbo\"]\n",
    "_=raw_hemo.pick(picks)\n",
    "raw_hemo.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "08e64aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['S2_D3 hbo', 'S2_D4 hbo', 'S3_D5 hbo', 'S3_D6 hbo'],)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hemo.ch_names, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "07c2fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0d4abf74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _ArrayFunctionDispatcher in module numpy:\n",
      "\n",
      "apply_along_axis(func1d, axis, arr, *args, **kwargs)\n",
      "    Apply a function to 1-D slices along the given axis.\n",
      "    \n",
      "    Execute `func1d(a, *args, **kwargs)` where `func1d` operates on 1-D arrays\n",
      "    and `a` is a 1-D slice of `arr` along `axis`.\n",
      "    \n",
      "    This is equivalent to (but faster than) the following use of `ndindex` and\n",
      "    `s_`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of indices::\n",
      "    \n",
      "        Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n",
      "        for ii in ndindex(Ni):\n",
      "            for kk in ndindex(Nk):\n",
      "                f = func1d(arr[ii + s_[:,] + kk])\n",
      "                Nj = f.shape\n",
      "                for jj in ndindex(Nj):\n",
      "                    out[ii + jj + kk] = f[jj]\n",
      "    \n",
      "    Equivalently, eliminating the inner loop, this can be expressed as::\n",
      "    \n",
      "        Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n",
      "        for ii in ndindex(Ni):\n",
      "            for kk in ndindex(Nk):\n",
      "                out[ii + s_[...,] + kk] = func1d(arr[ii + s_[:,] + kk])\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    func1d : function (M,) -> (Nj...)\n",
      "        This function should accept 1-D arrays. It is applied to 1-D\n",
      "        slices of `arr` along the specified axis.\n",
      "    axis : integer\n",
      "        Axis along which `arr` is sliced.\n",
      "    arr : ndarray (Ni..., M, Nk...)\n",
      "        Input array.\n",
      "    args : any\n",
      "        Additional arguments to `func1d`.\n",
      "    kwargs : any\n",
      "        Additional named arguments to `func1d`.\n",
      "    \n",
      "        .. versionadded:: 1.9.0\n",
      "    \n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray  (Ni..., Nj..., Nk...)\n",
      "        The output array. The shape of `out` is identical to the shape of\n",
      "        `arr`, except along the `axis` dimension. This axis is removed, and\n",
      "        replaced with new dimensions equal to the shape of the return value\n",
      "        of `func1d`. So if `func1d` returns a scalar `out` will have one\n",
      "        fewer dimensions than `arr`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    apply_over_axes : Apply a function repeatedly over multiple axes.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> def my_func(a):\n",
      "    ...     \"\"\"Average first and last element of a 1-D array\"\"\"\n",
      "    ...     return (a[0] + a[-1]) * 0.5\n",
      "    >>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
      "    >>> np.apply_along_axis(my_func, 0, b)\n",
      "    array([4., 5., 6.])\n",
      "    >>> np.apply_along_axis(my_func, 1, b)\n",
      "    array([2.,  5.,  8.])\n",
      "    \n",
      "    For a function that returns a 1D array, the number of dimensions in\n",
      "    `outarr` is the same as `arr`.\n",
      "    \n",
      "    >>> b = np.array([[8,1,7], [4,3,9], [5,2,6]])\n",
      "    >>> np.apply_along_axis(sorted, 1, b)\n",
      "    array([[1, 7, 8],\n",
      "           [3, 4, 9],\n",
      "           [2, 5, 6]])\n",
      "    \n",
      "    For a function that returns a higher dimensional array, those dimensions\n",
      "    are inserted in place of the `axis` dimension.\n",
      "    \n",
      "    >>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
      "    >>> np.apply_along_axis(np.diag, -1, b)\n",
      "    array([[[1, 0, 0],\n",
      "            [0, 2, 0],\n",
      "            [0, 0, 3]],\n",
      "           [[4, 0, 0],\n",
      "            [0, 5, 0],\n",
      "            [0, 0, 6]],\n",
      "           [[7, 0, 0],\n",
      "            [0, 8, 0],\n",
      "            [0, 0, 9]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.apply_along_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "233eecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_in_run(snirfpath, tsvpath):\n",
    "    events = [] \n",
    "    event_labels = [] \n",
    "    intensity,annots_df,onsets = load_files(snirfpath, tsvpath)\n",
    "    od = mne.preprocessing.nirs.optical_density(intensity)\n",
    "    raw_hemo = mne.preprocessing.nirs.beer_lambert_law(od)\n",
    "    picks = [\"S2_D3 hbo\", \"S2_D4 hbo\", \"S3_D5 hbo\", \"S3_D6 hbo\"]\n",
    "    raw_hemo.pick(picks) # select only subset of channels\n",
    "    # For each video\n",
    "    for i in range(annots_df.shape[0]):\n",
    "        onset,trial_type = float(annots_df['Onset'][i]),str(annots_df['trial_type'][i])\n",
    "        if trial_type != 'rest':\n",
    "            print(f\"Processing trial_type {trial_type}\")\n",
    "            onset_next_rest = float(annots_df['Onset'][i+1])\n",
    "            assert str(annots_df['trial_type'][i+1]) == 'rest' # sanity check\n",
    "            # Split up video into 5second events, add events to list\n",
    "            for idx in range(int(15*SR),int((onset_next_rest - onset)*SR),int(ETIME*SR)):\n",
    "                e = raw_hemo[:][0][:,idx:idx+int(ETIME*SR)]\n",
    "                win = np.hamming(e.shape[1])\n",
    "                e = np.apply_along_axis(lambda x:x*win,1,e)\n",
    "                e = abs(np.fft.rfft(e,axis=1))**2 # PSD\n",
    "                e = np.log10(e) # log PSD \n",
    "                e = e[:,1:e.shape[1]//2] # drop DC and high freqs\n",
    "                e += 11 # normalize ish\n",
    "#                 plt.plot(e.T)\n",
    "#                 plt.show()\n",
    "                events.append(e)\n",
    "                event_labels.append(event_labels_dic[trial_type])\n",
    "    return events,event_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8c7906c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/steve/Documents/code/neuroimagery2023/signal-classifier/data_movie/steve-scan1-Sep-21-2023-6-35-PM_run02.snirf\n",
      "Reading 0 ... 13012  =      0.000 ...  1301.200 secs...\n",
      "Processing trial_type planetearth\n",
      "Processing trial_type animatedshorts\n",
      "Processing trial_type 3b1b\n",
      "Processing trial_type mandarinvocab\n",
      "Got events from run2, len=205\n",
      "Loading /Users/steve/Documents/code/neuroimagery2023/signal-classifier/data_movie/steve-scan1-Sep-21-2023-7-09-PM_run03.snirf\n",
      "Reading 0 ... 12726  =      0.000 ...  1272.600 secs...\n",
      "Processing trial_type planetearth\n",
      "Processing trial_type 3b1b\n",
      "Processing trial_type jackychan\n",
      "Processing trial_type jackychan\n",
      "Got events from run3, len=192\n",
      "Loading /Users/steve/Documents/code/neuroimagery2023/signal-classifier/data_movie/steve-scan2-Sep-21-2023-8-11-PM_run04_forhead.snirf\n",
      "Reading 0 ... 14487  =      0.000 ...  1448.700 secs...\n",
      "Processing trial_type mandarinvocab\n",
      "Processing trial_type planetearth\n",
      "Processing trial_type planetearth\n",
      "Processing trial_type planetearth\n",
      "Processing trial_type planetearth\n",
      "Processing trial_type mandarinvocab\n",
      "Got events from run4-forhead, len=226\n",
      "Loading /Users/steve/Documents/code/neuroimagery2023/signal-classifier/data_movie/steve-scan3-Sep-21-2023-8-35-PM_run05.snirf\n",
      "Reading 0 ... 11960  =      0.000 ...  1196.000 secs...\n",
      "Processing trial_type animatedshorts\n",
      "Processing trial_type mandarinvocab\n",
      "Processing trial_type jackychan\n",
      "Got events from run5, len=158\n",
      "Loading /Users/steve/Documents/code/neuroimagery2023/signal-classifier/data_movie/steve-scan4-Sep-21-2023-8-58-PM_run06_forhead.snirf\n",
      "Reading 0 ... 11524  =      0.000 ...  1152.400 secs...\n",
      "Processing trial_type jackychan\n",
      "Processing trial_type mandarinvocab\n",
      "Processing trial_type animatedshorts\n",
      "Got events from run6-forhead, len=164\n",
      "Loading /Users/steve/Documents/code/neuroimagery2023/signal-classifier/data_movie/steve-scan5-Sep-21-2023-9-20-PM_run07.snirf\n",
      "Reading 0 ... 11824  =      0.000 ...  1182.400 secs...\n",
      "Processing trial_type mandarinvocab\n",
      "Processing trial_type 3b1b\n",
      "Got events from run7, len=197\n"
     ]
    }
   ],
   "source": [
    "runids = [\"run2\",\"run3\",\"run4-forhead\",\"run5\",\"run6-forhead\",\"run7\"]\n",
    "\n",
    "snirfs = [\"steve-scan1-Sep-21-2023-6-35-PM_run02.snirf\",\n",
    "          \"steve-scan1-Sep-21-2023-7-09-PM_run03.snirf\",\n",
    "         \"steve-scan2-Sep-21-2023-8-11-PM_run04_forhead.snirf\",\n",
    "         \"steve-scan3-Sep-21-2023-8-35-PM_run05.snirf\",\n",
    "         \"steve-scan4-Sep-21-2023-8-58-PM_run06_forhead.snirf\",\n",
    "         \"steve-scan5-Sep-21-2023-9-20-PM_run07.snirf\"]\n",
    "\n",
    "tsvs = [\"timestamps_run02.tsv\",\n",
    "        \"timestamps_run03.tsv\",\n",
    "       \"timestamps_run04_forhead.tsv\",\n",
    "       \"timestamps_run05.tsv\",\n",
    "       \"timestamps_run06_forhead.tsv\",\n",
    "       \"timestamps_run07.tsv\"]\n",
    "\n",
    "events, labels, runs = [],[],[]\n",
    "\n",
    "for runid,snirf,tsv in zip(runids,snirfs,tsvs):\n",
    "    snirfpath = join(\"data_movie\",snirf)\n",
    "    tsvpath = join(\"data_movie\",tsv)\n",
    "    events_run, labels_run = get_events_in_run(snirfpath,tsvpath)\n",
    "    assert len(events_run) == len(labels_run) # sanity\n",
    "    print(f\"Got events from {runid}, len={len(events_run)}\")\n",
    "    events.append(events_run)\n",
    "    labels.append(labels_run)\n",
    "    runs.append(runid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a61d0e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.16666666666667"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(205+192+226+158+164+197)*ETIME/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b776fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for runid,events_run,labels_run in zip(runs,events,labels):\n",
    "    # serialize all events and labels \n",
    "    np.save(f\"events/events_{runid}.npy\",np.asarray(events_run))\n",
    "    np.save(f\"events/event_labels_{runid}.npy\",np.asarray(labels_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9fad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
